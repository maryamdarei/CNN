{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maryamdarei/CNN/blob/main/NEW_CNN_from_github%2C_with_GRADCAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2654fd3c",
      "metadata": {
        "id": "2654fd3c"
      },
      "source": [
        "It iS a package, from Githup:\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "CNN trained on a small imagenet dataset\n",
        "Imagenette is a subset of 10 easily classified classes from \n",
        "Imagenet (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute).\n",
        "https://github.com/fastai/imagenette\n",
        "Download the Imagenette dataset from Github to Imageneet folder\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "https://github.com/alexcpn/cnn_train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e823be0a",
      "metadata": {
        "id": "e823be0a"
      },
      "outputs": [],
      "source": [
        "\n",
        "import logging as log\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from matplotlib import ticker\n",
        "\n",
        "from models import alexnet, mycnn, mycnn2, resnet\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c44ea7ba",
      "metadata": {
        "id": "c44ea7ba"
      },
      "outputs": [],
      "source": [
        "\n",
        "log.basicConfig(format=\"%(asctime)s %(message)s\", level=log.INFO)\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd5e1510",
      "metadata": {
        "id": "cd5e1510"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define relevant variables for the ML task\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20  # actual 20 epochs\n",
        "workers = 0\n",
        "pin_memory = False\n",
        "batch_size = 64\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "torch.cuda.synchronize()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "637c7b51",
      "metadata": {
        "id": "637c7b51"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == \"cuda\":\n",
        "    deviceid = torch.cuda.current_device()\n",
        "    log.info(f\"Gpu device {torch.cuda.get_device_name(deviceid)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbb54221",
      "metadata": {
        "id": "dbb54221"
      },
      "source": [
        "-------------------------------------------------------------------------------------------------------\n",
        "# Select the model you want to train\n",
        "-------------------------------------------------------------------------------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc27c73",
      "metadata": {
        "id": "4bc27c73"
      },
      "outputs": [],
      "source": [
        "modelname = \"alexnet_\"\n",
        "\n",
        "if modelname == \"mycnn_\":\n",
        "    # Actual image size is 432*320\n",
        "    model = mycnn.MyCNN().to(device)\n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "if modelname == \"mycnn2_\":\n",
        "    # Actual image size is 432*320\n",
        "    model = mycnn2.MyCNN2().to(device)\n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "if modelname == \"alexnet_\":\n",
        "    # Alexnet model works well for CIFAR-10 when input is scaled to 227x227\n",
        "    model = alexnet.AlexNet().to(device)\n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "\n",
        "if modelname == \"RestNet50_\":\n",
        "    model = resnet.ResNet50(img_channel=3, num_classes=10).to(device)\n",
        "    # resizing lower to keep it in memory\n",
        "    resize_to = transforms.Resize((227, 227))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbfa0e7f",
      "metadata": {
        "id": "bbfa0e7f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------------------------------------------------------------------------------------------------------\n",
        "# Load the data from image folder\n",
        "# -------------------------------------------------------------------------------------------------------\n",
        "\n",
        "data_dir = \"./imagenette2-320\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "normalize_transform = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "        resize_to,\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomGrayscale(0.5),\n",
        "        transforms.ToTensor(),\n",
        "        normalize_transform,\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_dir = os.path.join(data_dir, \"val\")\n",
        "\n",
        "val_transforms = transforms.Compose(\n",
        "    [resize_to, transforms.ToTensor(), normalize_transform]\n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\n",
        "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8987a4e",
      "metadata": {
        "id": "b8987a4e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -----------------------------------------------------------------------------------------------------\n",
        "# Order the categories as per how Dataloader loads it\n",
        "# -----------------------------------------------------------------------------------------------------\n",
        "\n",
        "foldername_to_class = {\n",
        "    \"dogs50A-train\": \"dog\",\n",
        "    \"n01440764\": \"tench\",\n",
        "    \"n02979186\": \"cassette player\",\n",
        "    \"n03000684\": \"chain saw\",\n",
        "    \"n03028079\": \"church\",\n",
        "    \"n03394916\": \"French horn\",\n",
        "    \"n03417042\": \"garbage truck\",\n",
        "    \"n03425413\": \"gas pump\",\n",
        "    \"n03445777\": \"golf ball\",\n",
        "    \"n03888257\": \"parachute\",\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f0ce32",
      "metadata": {
        "id": "88f0ce32"
      },
      "outputs": [],
      "source": [
        "# sort as value to fit the directory order to labels to be sure\n",
        "print(\"Image to Folder Index\", train_dataset.class_to_idx)\n",
        "sorted_vals = dict(sorted(train_dataset.class_to_idx.items(), key=lambda item: item[1]))\n",
        "categories = []\n",
        "for key in sorted_vals:\n",
        "    classname = foldername_to_class[key]\n",
        "    categories.append(classname)\n",
        "\n",
        "log.info(f\"Categories {categories}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b0007a5",
      "metadata": {
        "id": "0b0007a5"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------------------------------------------------\n",
        "# Initialise the data loaders\n",
        "# -------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# ImageFile.LOAD_TRUNCATED_IMAGES = True # Use the data_checker.py and remove bad files instead of using this\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,  # IMPORTANT otherwise the data is not shuffled\n",
        "    num_workers=workers,\n",
        "    pin_memory=pin_memory,\n",
        "    sampler=None,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ecd5637",
      "metadata": {
        "id": "8ecd5637"
      },
      "outputs": [],
      "source": [
        "\n",
        "# initialize our optimizer and loss function\n",
        "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "lossFn = nn.CrossEntropyLoss()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed2d719a",
      "metadata": {
        "id": "ed2d719a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------------------------------------------------------------------------------------------------------\n",
        "# Train the model\n",
        "# -------------------------------------------------------------------------------------------------------\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    log.info(f\"Shape of X [N, C, H, W]: {images.shape}\")\n",
        "    log.info(f\"Shape of y: {labels.shape} {labels.dtype}\")\n",
        "    # test one flow\n",
        "    # pred = model(x)\n",
        "    # loss = lossFn(pred, y)\n",
        "    break\n",
        "total_step = len(train_loader)\n",
        "log.info(f\"Total steps: {total_step}\")\n",
        "\n",
        "stepsize = total_step // 100\n",
        "if stepsize < 10:\n",
        "    stepsize = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1df759",
      "metadata": {
        "id": "af1df759"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Write training matrics to Tensorboard\n",
        "writer = SummaryWriter()\n",
        "\n",
        "# loop over our epochs\n",
        "for epoch in range(0, num_epochs):\n",
        "    # set the model in training mode\n",
        "    model.train()  # IMPORTANT otherwise the model is not in training mode\n",
        "    # initialize the total training and validation loss\n",
        "    totalTrainLoss = 0\n",
        "    totalValLoss = 0\n",
        "    # initialize the number of correct predictions in the training\n",
        "    # and validation step\n",
        "    trainAccuracy = 0\n",
        "    totalTrainAccuracy = 0\n",
        "    valCorrect = 0\n",
        "\n",
        "    # loop over the training set\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        try:\n",
        "            # Train in auto-mode with 16 bit mode\n",
        "            # with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "            # Train in normal mode\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=torch.float32):\n",
        "                # send the input to the device\n",
        "                (images, labels) = (images.to(device), labels.to(device))\n",
        "                # perform a forward pass and calculate the training loss\n",
        "                outputs = model(images)\n",
        "                # output is float16 because linear layers autocast to float16.\n",
        "                # assert outputs.dtype is torch.float16 or 64\n",
        "\n",
        "                loss = lossFn(outputs, labels)\n",
        "                # zero out the gradients, perform the backpropagation step,\n",
        "                # and update the weights\n",
        "                writer.add_scalar(\"Loss/train\", loss,  (epoch * total_step)+(i+1))\n",
        "                opt.zero_grad()  # IMPORTANT otherwise the gradients of previous batches are not zeroed out\n",
        "        except Exception as e:\n",
        "            log.error(f\"Exception in data processing- skip and continue = {e}\")\n",
        "        loss.backward()\n",
        "        totalTrainLoss += loss\n",
        "        opt.step()\n",
        "        # Get the predicted values\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        trainAccuracy = (predicted == labels).float().sum().item()\n",
        "        trainAccuracy = 100 * trainAccuracy / labels.size(0)\n",
        "        writer.add_scalar(\"Accuracy/train\", trainAccuracy,(epoch * total_step)+(i+1))\n",
        "        totalTrainAccuracy += trainAccuracy\n",
        "        # if (i // stepsize) % 10 == 0:\n",
        "        log.info(\n",
        "            \"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f} Accuracy: {:.4f}\".format(\n",
        "                epoch + 1, num_epochs, i + 1, total_step, loss, trainAccuracy\n",
        "            )\n",
        "        )\n",
        "\n",
        "    avgTrainLoss = totalTrainLoss / len(train_loader)\n",
        "    avgAccuracy = totalTrainAccuracy / len(train_loader)\n",
        "    log.info(\n",
        "        \"--->Epoch [{}/{}], Average Loss: {:.4f} Average Accuracy: {:.4f}\".format(\n",
        "            epoch + 1, num_epochs, avgTrainLoss, avgAccuracy\n",
        "        )\n",
        "    )\n",
        "    # End Epoch loop\n",
        "writer.flush()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ba9c01",
      "metadata": {
        "id": "27ba9c01"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the model\n",
        "path = \"cnn/saved_models/\"\n",
        "model_save_name = path + modelname + datetime.now().strftime(\"%H:%M_%B%d%Y\")\n",
        "torch.save(model.state_dict(), model_save_name + \".pth\")\n",
        "log.info(f\"Model {modelname} saved as {model_save_name}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1831a49",
      "metadata": {
        "id": "f1831a49"
      },
      "outputs": [],
      "source": [
        "# Generate the Confusion Matrix\n",
        "\n",
        "confusion_matrix = np.zeros((len(categories), len(categories)))\n",
        "\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    model.eval()  # IMPORTANT set model to eval mode before inference\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # ------------------------------------------------------------------------------------------\n",
        "        # Predict for the batch of images\n",
        "        # ------------------------------------------------------------------------------------------\n",
        "        outputs = model(\n",
        "            images\n",
        "        )  # Outputs= torch.Size([64, 10]) Probability of each of the 10 classes\n",
        "        _, predicted = torch.max(\n",
        "            outputs.data, 1\n",
        "        )  # get the class with the highest Probability out Given 1 per image # predicted= torch.Size([64])\n",
        "        # ------------------------------------------------------------------------------------------\n",
        "        #  Lets check also which classes are wrongly predicted with other classes  to create a MultiClass confusion matrix\n",
        "        # ------------------------------------------------------------------------------------------\n",
        "\n",
        "        mask = predicted != labels  # Wrongly predicted\n",
        "        wrong_predicted = torch.masked_select(predicted, mask)\n",
        "        wrong_labels = torch.masked_select(labels, mask)\n",
        "        wrongly_zipped = zip(wrong_labels, wrong_predicted)\n",
        "\n",
        "        mask = predicted == labels  # Rightly predicted\n",
        "        rightly_predicted = torch.masked_select(predicted, mask)\n",
        "        right_labels = rightly_predicted  # same torch.masked_select(labels,mask)\n",
        "        rightly_zipped = zip(right_labels, rightly_predicted)\n",
        "\n",
        "        # Note that this is for a single batch - add to the list associated with class\n",
        "        for _, j in enumerate(wrongly_zipped):\n",
        "            k = j[0].item()  # label\n",
        "            l = j[1].item()  # predicted\n",
        "            confusion_matrix[k][l] += 1\n",
        "\n",
        "        # Note that this is for a single batch - add to the list associated with class\n",
        "        for _, j in enumerate(rightly_zipped):\n",
        "            k = j[0].item()  # label\n",
        "            l = j[1].item()  # predicted\n",
        "            confusion_matrix[k][l] += 1\n",
        "\n",
        "    # print(\"Confusion Matrix1=\\n\",confusion_matrix)\n",
        "    # ------------------------------------------------------------------------------------------\n",
        "    # Print Confusion matrix in Pretty print format\n",
        "    # ------------------------------------------------------------------------------------------\n",
        "    print(categories)\n",
        "    for i in range(len(categories)):\n",
        "        for j in range(len(categories)):\n",
        "            print(f\"\\t{confusion_matrix[i][j]}\", end=\"\")\n",
        "        print(f\"\\t{categories[i]}\\n\", end=\"\")\n",
        "    # ------------------------------------------------------------------------------------------\n",
        "    # Calculate Accuracy per class\n",
        "    # ------------------------------------------------------------------------------------------\n",
        "    print(\"---------------------------------------\")\n",
        "    print(\n",
        "        f\"Accuracy/precision from confusion matrix is {round(confusion_matrix.trace()/confusion_matrix.sum(),2)}\"\n",
        "    )\n",
        "    print(\"---------------------------------------\")\n",
        "    for i in range(len(categories)):\n",
        "        print(\n",
        "            f\"---Accuracy for class {categories[i]} = {round(confusion_matrix[i][i]/confusion_matrix[i].sum(),2)}\"\n",
        "        )\n",
        "\n",
        "    # ---------------------------------------------------\n",
        "    # Plot this in a good figure\n",
        "    # ---------------------------------------------------\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    plt.title(\"Confusion Matrix\", fontsize=18)\n",
        "    ax.matshow(confusion_matrix, cmap=plt.cm.Blues, alpha=0.7)\n",
        "    ax.set_xticklabels([\"\"] + categories, rotation=90)\n",
        "    ax.set_yticklabels([\"\"] + categories)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    for i in range(confusion_matrix.shape[0]):\n",
        "        for j in range(confusion_matrix.shape[1]):\n",
        "            ax.text(\n",
        "                x=j,\n",
        "                y=i,\n",
        "                s=int(confusion_matrix[i, j]),\n",
        "                va=\"center\",\n",
        "                ha=\"center\",\n",
        "                size=\"xx-small\",\n",
        "            )\n",
        "            if i == j:\n",
        "                acc = round(confusion_matrix[i][i] / confusion_matrix[i].sum(), 2)\n",
        "                ax.text(\n",
        "                    x=len(categories) + 1,\n",
        "                    y=i,\n",
        "                    s=acc,\n",
        "                    va=\"center\",\n",
        "                    ha=\"center\",\n",
        "                    size=\"xx-small\",\n",
        "                )\n",
        "    plt.savefig(model_save_name + \"_cm.jpg\")\n",
        "\n",
        "    # correct = 0\n",
        "    # total = 0\n",
        "    # for images, labels in train_loader:\n",
        "    #     images = images.to(device)\n",
        "    #     labels = labels.to(device)\n",
        "    #     outputs = model(images)\n",
        "    #     _, predicted = torch.max(outputs.data, 1)\n",
        "    #     total += labels.size(0)\n",
        "    #     correct += (predicted == labels).float().sum().item()\n",
        "    # # this is not really not needed- but just to cross check if what we calculated during training is accurate\n",
        "    # print(\n",
        "    #     \"Accuracy of the network on the {} Train images: {} %\".format(\n",
        "    #         total, 100 * correct / total\n",
        "    #     )\n",
        "    # )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "Pre trained  model from tutorial modified from\n",
        "https://pytorch.org/hub/pytorch_vision_alexnet/\n",
        "And for imagenette small dataset\n",
        "Imagenet (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute).\n",
        "https://github.com/fastai/imagenette\n",
        "Load the Pre-trained models generated from test4_cnn_imagenet_small.py in the same folder\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Y7BjSa1zebVN"
      },
      "id": "Y7BjSa1zebVN"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from importlib.resources import path\n",
        "from PIL import Image\n",
        "from torchvision import transforms,datasets\n",
        "import torch\n",
        "from models import resnet, alexnet, mycnn, mycnn2\n",
        "import os\n"
      ],
      "metadata": {
        "id": "2vs5F_OqedWK"
      },
      "id": "2vs5F_OqedWK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_images = ['test-tench.jpg','fish_boy.jpg','test-church.jpg','test-garbagetruck.jpg','test-truck.jpg','test-dog.jpg','train_dog.png',\n",
        "\"test-englishspringer.jpg\",\"test_dogcartoon.jpg\",\"test_chaingsaw.jpg\",\"test_chainsawtrain.jpg\",\"test_frenchhorn.jpg\",\n",
        "\"test_frenchhorntrain.jpg\",\"test-golfball.jpg\"]\n",
        "\n",
        "\n",
        "data_dir = \"./imagenette2-320\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "train_dataset = datasets.ImageFolder(train_dir,[])\n"
      ],
      "metadata": {
        "id": "KevslBk5eiTc"
      },
      "id": "KevslBk5eiTc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------\n",
        "# Order the categories as per how Dataloader loads it\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "\n",
        "foldername_to_class = { 'dogs50A-train' : \"dog\",\n",
        "                        'n01440764': \"tench\",\n",
        "                        'n02979186': \"cassette player\", \n",
        "                        'n03000684': \"chain saw\",\n",
        "                        'n03028079': \"church\",\n",
        "                        'n03394916': \"French horn\",\n",
        "                        'n03417042': \"garbage truck\",\n",
        "                        'n03425413': \"gas pump\",\n",
        "                        'n03445777':  \"golf ball\",\n",
        "                        'n03888257': \"parachute\" }"
      ],
      "metadata": {
        "id": "9Df3Mi7cemWR"
      },
      "id": "9Df3Mi7cemWR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort as value to fit the directory order to labels to be sure\n",
        "print(\"Image to Folder Index\",train_dataset.class_to_idx)\n",
        "sorted_vals = dict(sorted(train_dataset.class_to_idx.items(), key=lambda item: item[1]))\n",
        "categories =[]\n",
        "for key in sorted_vals:\n",
        "    classname = foldername_to_class[key]\n",
        "    categories.append(classname)\n",
        "\n",
        "print(\"Categories\",categories)"
      ],
      "metadata": {
        "id": "YC5otaCceqhD"
      },
      "id": "YC5otaCceqhD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Choose a saved Model - assign the name you want to test with\n",
        "# (assuming that you have trained the models)\n",
        "modelname = \"resnet50\"\n",
        "\n",
        "if modelname == \"mycnn\":\n",
        "    model = mycnn.MyCNN()\n",
        "    path = \"mycnn_18:07_October142022.pth\" \n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "if modelname == \"mycnn2\":\n",
        "    model = mycnn2.MyCNN2()\n",
        "    path =\"mycnn2_16:43_October182022.pth\"\n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "if modelname == \"alexnet\":\n",
        "    model = alexnet.AlexNet()\n",
        "    path = \"alexnet_15:08_August082022.pth\"\n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "if modelname == \"resnet50\":\n",
        "    model = resnet.ResNet50(img_channel=3, num_classes=10)\n",
        "    path =\"RestNet50_11:45_November072022.pth\"\n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "\n",
        "path = \"cnn/saved_models/\" +path\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval()\n",
        "\n",
        "for filename in test_images:\n",
        "    input_image = Image.open('./test-images/'+filename)\n",
        "    preprocess = transforms.Compose(\n",
        "        [\n",
        "            resize_to,\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "            ),  # IMPORTANT: normalize for pretrained models\n",
        "        ]\n",
        "    )\n",
        "    input_tensor = preprocess(input_image)\n",
        "    input_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model\n",
        "\n",
        "    # move the input and model to GPU for speed if available\n",
        "    if torch.cuda.is_available():\n",
        "        input_batch = input_batch.to(\"cuda\")\n",
        "        model.to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    # print(probabilities)\n",
        "    print(f\"Detecting for class {filename} model {modelname}\")\n",
        "    print(\"--------------------------------\")\n",
        "    # Show top categories per image\n",
        "    top5_prob, top5_catid = torch.topk(probabilities, 2)\n",
        "    for i in range(top5_prob.size(0)):\n",
        "        print(categories[top5_catid[i]], top5_prob[i].item())\n",
        "    print(\"--------------------------------\")"
      ],
      "metadata": {
        "id": "wxsfR00reuyD"
      },
      "id": "wxsfR00reuyD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility to check Precision and Recall of a  trained model Author - Alex Punnen**"
      ],
      "metadata": {
        "id": "DNHyy9gEfiJM"
      },
      "id": "DNHyy9gEfiJM"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import logging as log\n",
        "from models import resnet, alexnet, mycnn, mycnn2\n",
        "import os\n",
        "import sklearn.metrics as skmc #this has confusion matrix but need to give all in a shot ?\n"
      ],
      "metadata": {
        "id": "NZ_utDoZfjVn"
      },
      "id": "NZ_utDoZfjVn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log.basicConfig(format=\"%(asctime)s %(message)s\", level=log.INFO)\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "5RW8JlY5f1y6"
      },
      "id": "5RW8JlY5f1y6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == \"cuda\":\n",
        "    deviceid = torch.cuda.current_device()\n",
        "    log.info(f\"Gpu device {torch.cuda.get_device_name(deviceid)}\")\n"
      ],
      "metadata": {
        "id": "jukP9e4gf_xl"
      },
      "id": "jukP9e4gf_xl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Choose a saved Model - assign the name you want to test with\n",
        "# (assuming that you have trained the models)\n",
        "modelname = \"resnet50\"\n",
        "    \n",
        "if modelname == \"mycnn\":\n",
        "    model = mycnn.MyCNN()\n",
        "    path =  \"mycnn_11:49_October302022.pth\" \n",
        "    resize_to = transforms.Resize((150, 150))\n",
        "if modelname == \"mycnn2\":\n",
        "    model = mycnn2.MyCNN2()\n",
        "    path =\"mycnn2_16:43_October182022.pth\"\n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "if modelname == \"alexnet\":\n",
        "    model = alexnet.AlexNet()\n",
        "    path = \"./alexnet_15:08_August082022.pth\"\n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "if modelname == \"resnet50\":\n",
        "    model = resnet.ResNet50(img_channel=3, num_classes=10)\n",
        "    path = \"./RestNet50_11:43_October072022.pth\"   # trained with more dog images from imagenet\n",
        "    path =\"./RestNet50_11:45_November072022.pth\"\n",
        "    resize_to = transforms.Resize((227, 227))\n",
        "\n",
        "path = \"cnn/saved_models/\" +path\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "tV0p90TRf_1j"
      },
      "id": "tV0p90TRf_1j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------------------------------------\n",
        "# Load the data from image folder\n",
        "# -------------------------------------------------------------------------------------------------------\n",
        "\n",
        "data_dir = \"./imagenette2-320\"\n",
        "\n",
        "\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "normalize_transform = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose(\n",
        "    [resize_to, \n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomGrayscale(),\n",
        "    transforms.ToTensor(), normalize_transform]\n",
        ")\n",
        "\n",
        "val_dir = os.path.join(data_dir, \"val\")\n",
        "\n",
        "val_transforms = transforms.Compose(\n",
        "    [resize_to, transforms.ToTensor(), normalize_transform]\n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n"
      ],
      "metadata": {
        "id": "1tNJtNXef_4y"
      },
      "id": "1tNJtNXef_4y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------\n",
        "# Order the categories as per how Dataloader loads it\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "\n",
        "foldername_to_class = { 'dogs50A-train' : \"dog\",\n",
        "                        'n01440764': \"tench\",\n",
        "                        'n02979186': \"cassette player\", \n",
        "                        'n03000684': \"chain saw\",\n",
        "                        'n03028079': \"church\",\n",
        "                        'n03394916': \"French horn\",\n",
        "                        'n03417042': \"garbage truck\",\n",
        "                        'n03425413': \"gas pump\",\n",
        "                        'n03445777':  \"golf ball\",\n",
        "                        'n03888257': \"parachute\" }\n",
        "\n",
        "# Imagenette classes - labels for better description\n",
        "categories_ref = [\n",
        "    \"English springer\",\n",
        "    \"tench\",\n",
        "    \"cassette player\",\n",
        "    \"chain saw\",\n",
        "    \"church\",\n",
        "    \"French horn\",\n",
        "    \"garbage truck\",\n",
        "    \"gas pump\",\n",
        "    \"golf ball\",\n",
        "    \"parachute\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "1PDnIwjmgXZM"
      },
      "id": "1PDnIwjmgXZM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort as value to fit the directory order to labels to be sure\n",
        "print(\"Image to Folder Index\",train_dataset.class_to_idx)\n",
        "sorted_vals = dict(sorted(train_dataset.class_to_idx.items(), key=lambda item: item[1]))\n",
        "categories =[]\n",
        "for key in sorted_vals:\n",
        "    classname = foldername_to_class[key]\n",
        "    categories.append(classname)\n",
        "\n",
        "print(\"Categories\",categories)\n"
      ],
      "metadata": {
        "id": "68KJ5XYHgXdN"
      },
      "id": "68KJ5XYHgXdN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------------------------------------\n",
        "# Initialise the data loaders\n",
        "# -------------------------------------------------------------------------------------------------------\n",
        "\n",
        "workers = 2\n",
        "pin_memory = True\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True, #IMPORTANT otherwise the data is not shuffled\n",
        "    num_workers=workers,\n",
        "    pin_memory=pin_memory,\n",
        "    sampler=None,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ],
      "metadata": {
        "id": "5TWhGE5TgXgE"
      },
      "id": "5TWhGE5TgXgE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------------------------------------\n",
        "#  Test the model - Find accuracy and per class\n",
        "# -------------------------------------------------------------------------------------------------------\n",
        "\n",
        "print(\"Image to Folder Index\",train_dataset.class_to_idx)\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    model.to(\"cuda\")\n",
        "\n",
        "confusion_matrix = np.zeros((len(categories),len(categories)))\n",
        "\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    model.eval() #IMPORTANT set model to eval mode before inference\n",
        "    # correct = 0\n",
        "    # total = 0\n",
        "\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # ------------------------------------------------------------------------------------------\n",
        "        # Predict for the batch of images\n",
        "        # ------------------------------------------------------------------------------------------\n",
        "        outputs = model(images)  #Outputs= torch.Size([64, 10]) Probability of each of the 10 classes\n",
        "        _, predicted = torch.max(outputs.data, 1) # get the class with the highest Probability out Given 1 per image # predicted= torch.Size([64])\n",
        "        # total += labels.size(0) #labels= torch.Size([64])  This is the truth value per image - the right class\n",
        "        # correct += (predicted == labels).float().sum().item()  # Find which are correctly classified\n",
        "        \n",
        "        # Below illustrates the above Torch Tensor semantics\n",
        "        # >>> import torch\n",
        "        # >>> some_integers = torch.tensor((2, 3, 5, 7, 11, 13, 17, 19))\n",
        "        # >>> some_integers3 = torch.tensor((12, 3, 5, 7, 11, 13, 17, 19))\n",
        "        # >>> (some_integers ==some_integers3)*(some_integers == 3)\n",
        "        # tensor([False,  True, False, False, False, False, False, False])\n",
        "        # >>> ((some_integers ==some_integers3)*(some_integers >12)).sum().item()\n",
        "        # 3\n",
        "        \n",
        "        # ------------------------------------------------------------------------------------------\n",
        "        #  Lets check also which classes are wrongly predicted with other classes  to create a MultiClass confusion matrix\n",
        "        # ------------------------------------------------------------------------------------------\n",
        "\n",
        "        mask=(predicted != labels) # Wrongly predicted\n",
        "        wrong_predicted =torch.masked_select(predicted,mask)\n",
        "        wrong_labels =torch.masked_select(labels,mask)\n",
        "        wrongly_zipped = zip(wrong_labels,wrong_predicted)\n",
        "\n",
        "        mask=(predicted == labels) # Rightly predicted\n",
        "        rightly_predicted =torch.masked_select(predicted,mask)\n",
        "        right_labels =rightly_predicted #same torch.masked_select(labels,mask)\n",
        "        rightly_zipped = zip(right_labels,rightly_predicted)\n",
        "        \n",
        "        # Note that this is for a single batch - add to the list associated with class\n",
        "        for _,j in enumerate(wrongly_zipped):\n",
        "            k = j[0].item() # label\n",
        "            l = j[1].item() # predicted\n",
        "            confusion_matrix[k][l] +=1\n",
        "       \n",
        "        # Note that this is for a single batch - add to the list associated with class\n",
        "        for _,j in enumerate(rightly_zipped):\n",
        "            k = j[0].item() # label\n",
        "            l = j[1].item() # predicted\n",
        "            confusion_matrix[k][l] +=1\n",
        "    \n",
        "    #print(\"Confusion Matrix1=\\n\",confusion_matrix)\n",
        "    # ------------------------------------------------------------------------------------------\n",
        "    # Print Confusion matrix in Pretty print format\n",
        "    # ------------------------------------------------------------------------------------------\n",
        "    print(categories)\n",
        "    for i in range(len(categories)):\n",
        "        for j in range(len(categories)):\n",
        "            print(f\"\\t{confusion_matrix[i][j]}\",end='')\n",
        "        print(f\"\\t{categories[i]}\\n\",end='')\n",
        "    # ------------------------------------------------------------------------------------------\n",
        "    # Calculate Accuracy per class\n",
        "    # ------------------------------------------------------------------------------------------\n",
        "    print(\"---------------------------------------\")\n",
        "    print(f\"Accuracy/precision from confusion matrix is {round(confusion_matrix.trace()/confusion_matrix.sum(),2)}\")\n",
        "    print(\"---------------------------------------\")\n",
        "    for i in range(len(categories)):\n",
        "        print(f\"---Accuracy for class {categories[i]} = {round(confusion_matrix[i][i]/confusion_matrix[i].sum(),2)}\")\n",
        "    \n",
        "    # ---------------------------------------------------\n",
        "    # Plot this in a good figure\n",
        "    # ---------------------------------------------------\n",
        "        \n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    plt.title('Confusion Matrix', fontsize=18)\n",
        "    ax.matshow(confusion_matrix, cmap=plt.cm.Blues, alpha=0.7)\n",
        "    ax.set_xticklabels([''] + categories,rotation=90)\n",
        "    ax.set_yticklabels([''] + categories)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    for i in range(confusion_matrix.shape[0]):\n",
        "        for j in range(confusion_matrix.shape[1]):\n",
        "            ax.text(x=j, y=i,s=int(confusion_matrix[i, j]), va='center', ha='center', size='xx-small')\n",
        "            if ( i==j):\n",
        "                acc = round(confusion_matrix[i][i]/confusion_matrix[i].sum(),2)\n",
        "                ax.text(x=len(categories)+1, y=i,s=acc, va='center', ha='center', size='xx-small')\n",
        "    plt.savefig(\"confusion_matrix_\"+modelname +\".jpg\")\n",
        "\n",
        "    # correct = 0\n",
        "    # total = 0\n",
        "    # for images, labels in train_loader:\n",
        "    #     images = images.to(device)\n",
        "    #     labels = labels.to(device)\n",
        "    #     outputs = model(images)\n",
        "    #     _, predicted = torch.max(outputs.data, 1)\n",
        "    #     total += labels.size(0)\n",
        "    #     correct += (predicted == labels).float().sum().item()\n",
        "    # # this is not really not needed- but just to cross check if what we calculated during training is accurate\n",
        "    # print(\n",
        "    #     \"Accuracy of the network on the {} Train images: {} %\".format(\n",
        "    #         total, 100 * correct / total\n",
        "    #     )\n",
        "    # )\n",
        "\n"
      ],
      "metadata": {
        "id": "0B8Lwz2Kg2Kj"
      },
      "id": "0B8Lwz2Kg2Kj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Model Explain-ability GradCam***\n",
        "Gradcam helps one visualize which parts of the images are important for the CNN when it classifies an object with high probability. After testing a model, you can use this to visualize and debug the test results\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\n",
        "\n",
        "Using Grad CAM libray to visualize the gradients of the last layer\n",
        "and to see if the model has learned the features of the images"
      ],
      "metadata": {
        "id": "VBku6avje6oR"
      },
      "id": "VBku6avje6oR"
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_grad_cam import (\n",
        "    GradCAM,\n",
        "    HiResCAM,\n",
        "    ScoreCAM,\n",
        "    GradCAMPlusPlus,\n",
        "    AblationCAM,\n",
        "    XGradCAM,\n",
        "    EigenCAM,\n",
        "    FullGrad,\n",
        ")\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "\n",
        "from importlib.resources import path\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "import torch\n",
        "from models import resnet, alexnet, mycnn, mycnn2\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "I-xOowrHeu1z"
      },
      "id": "I-xOowrHeu1z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------\n",
        "# Order the categories as per how Dataloader loads it\n",
        "#-----------------------------------------------------------------------------------------------------\n",
        "data_dir = \"./imagenette2-320\"\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "train_dataset = datasets.ImageFolder(train_dir,[])\n",
        "\n",
        "foldername_to_class = { 'dogs50A-train' : \"dog\",\n",
        "                        'n01440764': \"tench\",\n",
        "                        'n02979186': \"cassette player\", \n",
        "                        'n03000684': \"chain saw\",\n",
        "                        'n03028079': \"church\",\n",
        "                        'n03394916': \"French horn\",\n",
        "                        'n03417042': \"garbage truck\",\n",
        "                        'n03425413': \"gas pump\",\n",
        "                        'n03445777':  \"golf ball\",\n",
        "                        'n03888257': \"parachute\" }\n",
        "\n",
        "\n",
        "# sort as value to fit the directory order to labels to be sure\n",
        "print(\"Image to Folder Index\",train_dataset.class_to_idx)\n",
        "sorted_vals = dict(sorted(train_dataset.class_to_idx.items(), key=lambda item: item[1]))\n",
        "categories =[]\n",
        "for key in sorted_vals:\n",
        "    classname = foldername_to_class[key]\n",
        "    categories.append(classname)\n",
        "\n",
        "print(\"Categories\",categories)\n"
      ],
      "metadata": {
        "id": "8F9z65E4eu50"
      },
      "id": "8F9z65E4eu50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a saved Model - comment out the rest\n",
        "modelname = \"resnet50\"\n",
        "\n",
        "# Choose a saved Model - assign the name you want to test with\n",
        "# (assuming that you have trained the models)\n",
        "#modelname = \"resnet50\"\n",
        "resize_size =(1,1)\n",
        "if modelname == \"mycnn\":\n",
        "    resize_size = (227, 227)\n",
        "    model = mycnn.MyCNN()\n",
        "    path = \"mycnn_18:07_October142022.pth\"\n",
        "    path =\"mycnn_13:01_October272022.pth\" #dual class only\n",
        "    resize_to = transforms.Resize(resize_size)\n",
        "if modelname == \"mycnn2\":\n",
        "    resize_size = (227, 227)\n",
        "    model = mycnn2.MyCNN2()\n",
        "    path =\"mycnn2_16:43_October182022.pth\"\n",
        "    resize_to = transforms.Resize(resize_size)\n",
        "if modelname == \"alexnet\":\n",
        "    resize_size = (227,227)\n",
        "    model = alexnet.AlexNet()\n",
        "    path = \"alexnet_20:56_October102022.pth\"\n",
        "    resize_to = transforms.Resize(resize_size)\n",
        "if modelname == \"resnet50\":\n",
        "    model = resnet.ResNet50(img_channel=3, num_classes=10)\n",
        "    resize_size =(227,227)\n",
        "    #path = \"./RestNet50_12:26_August082022.pth\" # without augumentation\n",
        "    path = \"RestNet50_13:49_September102022.pth\" #with augumentation\n",
        "    path = \"RestNet50_16:54_October062022.pth\" #with cartoon dogs\n",
        "    path = \"RestNet50_11:43_October072022.pth\"   # trained with more dog images from imagenet\n",
        "    path =\"RestNet50_11:45_November072022.pth\" #227*227\n",
        "    resize_to = transforms.Resize(resize_size)\n",
        "\n",
        "path = \"cnn/saved_models/\" +path\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "1IJO6GV7iswO"
      },
      "id": "1IJO6GV7iswO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def flatten_model(modules):\n",
        "    def flatten_list(_2d_list):\n",
        "        flat_list = []\n",
        "        # Iterate through the outer list\n",
        "        for element in _2d_list:\n",
        "            if type(element) is list:\n",
        "                # If the element is of type list, iterate through the sublist\n",
        "                for item in element:\n",
        "                    flat_list.append(item)\n",
        "            else:\n",
        "                flat_list.append(element)\n",
        "        return flat_list\n",
        "\n",
        "    ret = []\n",
        "    try:\n",
        "        for _, n in modules:\n",
        "            ret.append(loopthrough(n))\n",
        "    except:\n",
        "        try:\n",
        "            if str(modules._modules.items()) == \"odict_items([])\":\n",
        "                ret.append(modules)\n",
        "            else:\n",
        "                for _, n in modules._modules.items():\n",
        "                    ret.append(loopthrough(n))\n",
        "        except:\n",
        "            ret.append(modules)\n",
        "    return flatten_list(ret)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uH-FOTGvjDpN"
      },
      "id": "uH-FOTGvjDpN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the target for the CAM layer; Add all the layers in the model\n",
        "target_layers =[]\n",
        "module_list =[module for module in model.modules()]\n",
        "\n",
        "\n",
        "flatted_list= flatten_model(module_list)\n",
        "\n",
        "\n",
        "print(\"------------------------\")\n",
        "for count, value in enumerate(flatted_list):\n",
        "    \n",
        "    if isinstance(value, (nn.Conv2d,nn.AvgPool2d,nn.BatchNorm2d)):\n",
        "    #if isinstance(value, (nn.Conv2d)):\n",
        "        print(count, value)\n",
        "        target_layers.append(value)\n",
        "\n",
        "print(\"------------------------\")\n"
      ],
      "metadata": {
        "id": "vYelsp78jIZF"
      },
      "id": "vYelsp78jIZF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative is to add specific layers and check\n",
        "# if modelname=='resnet50':\n",
        "#     #target_layers = [module_list[142],module_list[143],module_list[144],module_list[145],module_list[146],module_list[147]]\n",
        "#     target_layers = [module_list[35],module_list[36],module_list[37],module_list[38],module_list[39],module_list[40]]\n",
        "# if modelname=='mycnn':\n",
        "#     target_layers = [module_list[11],module_list[8],module_list[5],module_list[2],module_list[4],module_list[7],module_list[10],module_list[13]] # CNN and Avg pooling\n",
        "#     #target_layers = [module_list[11],module_list[8],module_list[5],module_list[2]] # CNN only\n",
        "\n",
        "    \n",
        "# Construct the CAM object once, and then re-use it on many images:\n",
        "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "fSpy9mwkjSKU"
      },
      "id": "fSpy9mwkjSKU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the images\n",
        "\n",
        "test_images = ['test-tench.jpg','fish_boy.jpg','test-church.jpg','test-garbagetruck.jpg','test-truck.jpg','test-dog.jpg','train_dog.png',\n",
        "\"test-englishspringer.jpg\",\"test_dogcartoon.jpg\",\"test_chaingsaw.jpg\",\"test_chainsawtrain.jpg\",\"test_frenchhorn.jpg\",\n",
        "\"test_frenchhorntrain.jpg\",\"test-golfball.jpg\"]\n",
        "\n",
        "for filename in test_images:\n",
        "    input_image = Image.open('./test-images/'+filename)\n",
        "\n",
        "    preprocess = transforms.Compose(\n",
        "        [\n",
        "            resize_to,\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "            ),  # IMPORTANT: normalize for pre-trained models\n",
        "        ]\n",
        "    )\n",
        "    input_tensor = preprocess(input_image)\n",
        "    print(\"Input Tensor Shape:\", input_tensor.shape)\n",
        "    input_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model\n",
        "    # move the input and model to GPU for speed if available\n",
        "    if torch.cuda.is_available():\n",
        "        input_batch = input_batch.to(\"cuda\")\n",
        "        model.to(\"cuda\")\n",
        "        input_tensor = input_tensor.to(\"cuda\")\n",
        "\n",
        "    # We have to specify the target we want to generate\n",
        "    # the Class Activation Maps for.\n",
        "    # If targets is None, the highest scoring category\n",
        "    # will be used for every image in the batch.\n",
        "    # Here we use ClassifierOutputTarget, but you can define your own custom targets\n",
        "\n",
        "    # That are, for example, combinations of categories, or specific outputs in a non standard model.\n",
        "    targets = [ClassifierOutputTarget(6)] #0 for finch ?\n",
        "\n",
        "    # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
        "    grayscale_cam = cam(input_batch, targets=None,aug_smooth=True)\n",
        "    #print( \"len grayscale_cam\",len(grayscale_cam),grayscale_cam.shape)\n",
        "\n",
        "    # In this example grayscale_cam has only one image in the batch:\n",
        "    grayscale_cam = grayscale_cam[0, :]\n",
        "    # from PIL import Image\n",
        "    # im = Image.fromarray(grayscale_cam)\n",
        "    # if im.mode != 'RGB':\n",
        "    #     im = im.convert('L')\n",
        "    # im.save(\"grayscale_cam.jpeg\"\n",
        "\n",
        "    img=np.array(input_image.resize(resize_size),np.float32)\n",
        "    img = img.reshape(img.shape[1],img.shape[0],img.shape[2])\n",
        "    #print(\"img shape\",img.shape,img.max())\n",
        "    img = img/255\n",
        "    visualization = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
        "    #cam_images = [show_cam_on_image(img, grayscale, use_rgb=True) for img, grayscale in zip(input_image, grayscale_cam)]\n",
        "    visualization = Image.fromarray(visualization)\n",
        "    out_file_name =\"cnn/gradcam_out/\" +modelname+ \"_\" + os.path.basename(filename)\n",
        "    visualization.save(out_file_name)\n",
        "    #print(\"Visualization saved- now trying to show (GUI mode)\")\n",
        "    im = Image.open(out_file_name)\n",
        "    im.show()\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "cKrczX2KjVl2"
      },
      "id": "cKrczX2KjVl2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}